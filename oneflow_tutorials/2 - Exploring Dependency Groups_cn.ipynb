{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fafb7f6",
   "metadata": {},
   "source": [
    "# Exploring Dependency Groups\n",
    "> 探索依赖关系组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ffcf934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "import oneflow as torch\n",
    "from flowvision.models import resnet18\n",
    "import oneflow_pruning as tp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93f4f573",
   "metadata": {},
   "source": [
    "### Grouping\n",
    "\n",
    "在这部分中，我们将深入研究“DependencyGraph”模块的细节，说明它在促进结构修剪方面的有效性。\n",
    "\n",
    "首先，让我们从ResNet-18中获取一组。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea4aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. prepare your model and example inputs\n",
    "model = resnet18(pretrained=True).eval()\n",
    "example_inputs = torch.randn(1,3,224,224)\n",
    "\n",
    "# 1. build dependency graph for resnet18\n",
    "DG = tp.DependencyGraph().build_dependency(model, example_inputs=example_inputs)\n",
    "\n",
    "# 2. Select some channels to prune. Here we prune the channels indexed by [2, 6, 9].\n",
    "pruning_idxs = pruning_idxs=[2, 6, 9]\n",
    "group = DG.get_pruning_group( model.conv1, tp.prune_conv_out_channels, idxs=pruning_idxs )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b719e024",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "在Torch-Pruning中，依赖关系被组织为可迭代列表。在给定的组中，用户执行的初始操作被认为是根操作。\n",
    "\n",
    "例如，如果我们试图修剪'model.conv1'操作，则组中的第一个依赖项将反映此操作，该操作修剪了conv1的输出通道。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d61396ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupItem(dep=prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)), idxs=[2, 6, 9])\n"
     ]
    }
   ],
   "source": [
    "print(group[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "692b3d64",
   "metadata": {},
   "source": [
    "每个组中的依赖关系都包括对应于要修剪的通道的修剪索引。\n",
    "\n",
    "在这里，我们旨在删除conv1的第2、第6和第9个通道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbfbf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep: prune_out_channels on conv1 (Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)) => prune_out_channels on bn1 (BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
      "Indices: [2, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dep:\", group[1][0])\n",
    "print(\"Indices:\", group[1][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d47a65cf",
   "metadata": {},
   "source": [
    "Let's delve deeper into the concept of dependency in DepGraph. In DepGraph a dependency is represented as an edge that connects two nodes, indicating the presence of inter-dependency. Each dependency maintains two pruning functions: 1) a trigger function, which is a pruning operation that breaks the dependency when solely applied, and 2) a handler function, which can repair the broken dependency caused by triggers.  \n",
    "\n",
    "For instance, consider the simple Conv-BN dependency between conv1 and bn1. If we remove an output channel of 'conv1', it becomes necessary to prune the corresponding channel of 'BN' as well. This dependency is clearly illustrated in the following example.\n",
    "\n",
    "\n",
    "In Torch-Pruning, dependencies are organized as an iterable list. In a given group, the initial operation performed by the user is considered the root operation. For example, if we try to prune the 'model.conv1' operation, the first dependency in the group will reflect this operation, which prunes the output channel of conv1.\n",
    "\n",
    "Each dependency in the group includes the pruning index corresponding to the channel to be pruned. Here, we aim to remove the 2nd, 6th, and 9th channels of conv1.\n",
    "\n",
    "让我们深入了解DepGraph中的依赖关系概念。在DepGraph中，依赖关系表示为连接两个节点的边，表示存在相互依赖关系。每个依赖关系维护两个修剪函数：1）触发函数，它是一个修剪操作，当单独应用时会打破依赖关系，2）处理程序函数，它可以修复由触发器引起的破坏的依赖关系。\n",
    "\n",
    "例如，考虑conv1和bn1之间的简单Conv-BN依赖关系。如果我们删除'conv1'的一个输出通道，则有必要同时修剪'BN'的相应通道。这种依赖关系在以下示例中清楚地说明了。\n",
    "\n",
    "每个组中的每个依赖关系都包括对应于要修剪的通道的修剪索引。在这里，我们的目标是删除conv1的第2、第6和第9个通道。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee248dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Node: Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "Target Node: BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "Trigger Function: <bound method ConvPruner.prune_out_channels of <oneflow_pruning.pruner.function.ConvPruner object at 0x7f7410066ee0>>\n",
      "Handler Function: <bound method BatchnormPruner.prune_out_channels of <oneflow_pruning.pruner.function.BatchnormPruner object at 0x7f7410066fd0>>\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Node:\", group[1][0].source.module) # group[1][0].source.module # get the nn.Module\n",
    "print(\"Target Node:\", group[1][0].target.module) # group[1][0].target.module # get the nn.Module\n",
    "print(\"Trigger Function:\", group[1][0].trigger)\n",
    "print(\"Handler Function:\", group[1][0].handler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b7f8d24",
   "metadata": {},
   "source": [
    "### Pruning with Dependency\n",
    "\n",
    "在Torch-Pruning中，我们可以“执行”依赖项以应用修剪的处理程序函数。在这里，我们只修剪第一个conv1，而不修复依赖项。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102e0de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx=[2, 6, 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 61, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = group[0][1]\n",
    "dep = group[0][0]\n",
    "print(f'{idx=}')\n",
    "dep(idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e4c8270",
   "metadata": {},
   "source": [
    "然而，如果我们尝试像往常一样进行模型 forward，将会出现错误，显示“running_mean应该包含61个元素而不是64个”。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a3e191",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Check failed: ((64,) == (61,)) \n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/functional/impl/nn_functor.cpp\", line 2634, in operator()\n    OpInterpUtil::Dispatch<one::Tensor>( *norm_eval_op_, {x, moving_mean_val, moving_variance_val, gamma_val, beta_val}, attrs)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/op_interpreter_util.cpp\", line 144, in Dispatch<oneflow::one::Tensor>\n    Dispatch<TensorTuple>(op_expr, inputs, ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/op_interpreter_util.cpp\", line 135, in Dispatch<oneflow::one::TensorTuple>\n    Dispatch(op_expr, inputs, outputs.get(), ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/op_interpreter.cpp\", line 103, in Apply\n    internal_->Apply(op_expr, inputs, outputs, ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/eager_local_op_interpreter.cpp\", line 83, in NaiveInterpret\n    [&]() -> Maybe<const LocalTensorInferResult> { LocalTensorMetaInferArgs ... mut_local_tensor_infer_cache()->GetOrInfer(infer_args)); }()\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/eager_local_op_interpreter.cpp\", line 86, in operator()\n    user_op_expr.mut_local_tensor_infer_cache()->GetOrInfer(infer_args)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/local_tensor_infer_cache.cpp\", line 209, in GetOrInfer\n    Infer(*user_op_expr, infer_args)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/local_tensor_infer_cache.cpp\", line 178, in Infer\n    user_op_expr.InferPhysicalTensorDesc( infer_args.attrs ... ) -> TensorMeta* { return &output_mut_metas.at(i); })\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_expr.cpp\", line 580, in InferPhysicalTensorDesc\n    physical_tensor_desc_infer_fn_(&infer_ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/user/ops/normalization_op.cpp\", line 159, in operator()\n    CheckParamTensorDesc(\"moving_mean\")\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/user/ops/normalization_op.cpp\", line 32, in operator()\n    CHECK_EQ_OR_RETURN(tensor_desc.shape(), shape)\nError Type: oneflow.ErrorProto.check_failed_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(model(torch\u001b[39m.\u001b[39;49mrandn(\u001b[39m1\u001b[39;49m,\u001b[39m3\u001b[39;49m,\u001b[39m224\u001b[39;49m,\u001b[39m224\u001b[39;49m)))\n",
      "File \u001b[0;32m~/miniconda3/envs/oneflow-dev-clang10-v2/lib/python3.8/site-packages/oneflow/nn/modules/module.py:218\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     bw_hook \u001b[39m=\u001b[39m flow\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mhooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, [])\n\u001b[1;32m    216\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m--> 218\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    219\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, args, res)\n",
      "File \u001b[0;32m~/miniconda3/envs/oneflow-dev-clang10-v2/lib/python3.8/site-packages/flowvision/models/resnet.py:294\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 294\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/oneflow-dev-clang10-v2/lib/python3.8/site-packages/flowvision/models/resnet.py:278\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    277\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)\n\u001b[0;32m--> 278\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbn1(x)\n\u001b[1;32m    279\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n\u001b[1;32m    280\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/oneflow-dev-clang10-v2/lib/python3.8/site-packages/oneflow/nn/modules/module.py:218\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     bw_hook \u001b[39m=\u001b[39m flow\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mhooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, [])\n\u001b[1;32m    216\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m--> 218\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    219\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n\u001b[1;32m    220\u001b[0m     result \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, args, res)\n",
      "File \u001b[0;32m~/miniconda3/envs/oneflow-dev-clang10-v2/lib/python3.8/site-packages/oneflow/nn/modules/batchnorm.py:137\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m     is_training \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_mean \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m) \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrunning_var \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    136\u001b[0m \u001b[39m# NOTE(lixiang): If it is training mode, pass running_mean and running_var directly to the functor layer.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[39mreturn\u001b[39;00m flow\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mnormalization(\n\u001b[1;32m    138\u001b[0m     x,\n\u001b[1;32m    139\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_mean,\n\u001b[1;32m    140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunning_var,\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m    142\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    143\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchannel_axis,\n\u001b[1;32m    144\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meps,\n\u001b[1;32m    145\u001b[0m     momentum\u001b[39m=\u001b[39;49mexponential_average_factor,\n\u001b[1;32m    146\u001b[0m     is_training\u001b[39m=\u001b[39;49mis_training,\n\u001b[1;32m    147\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Check failed: ((64,) == (61,)) \n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/functional/impl/nn_functor.cpp\", line 2634, in operator()\n    OpInterpUtil::Dispatch<one::Tensor>( *norm_eval_op_, {x, moving_mean_val, moving_variance_val, gamma_val, beta_val}, attrs)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/op_interpreter_util.cpp\", line 144, in Dispatch<oneflow::one::Tensor>\n    Dispatch<TensorTuple>(op_expr, inputs, ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/op_interpreter_util.cpp\", line 135, in Dispatch<oneflow::one::TensorTuple>\n    Dispatch(op_expr, inputs, outputs.get(), ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/op_interpreter.cpp\", line 103, in Apply\n    internal_->Apply(op_expr, inputs, outputs, ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/eager_local_op_interpreter.cpp\", line 83, in NaiveInterpret\n    [&]() -> Maybe<const LocalTensorInferResult> { LocalTensorMetaInferArgs ... mut_local_tensor_infer_cache()->GetOrInfer(infer_args)); }()\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_interpreter/eager_local_op_interpreter.cpp\", line 86, in operator()\n    user_op_expr.mut_local_tensor_infer_cache()->GetOrInfer(infer_args)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/local_tensor_infer_cache.cpp\", line 209, in GetOrInfer\n    Infer(*user_op_expr, infer_args)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/local_tensor_infer_cache.cpp\", line 178, in Infer\n    user_op_expr.InferPhysicalTensorDesc( infer_args.attrs ... ) -> TensorMeta* { return &output_mut_metas.at(i); })\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/core/framework/op_expr.cpp\", line 580, in InferPhysicalTensorDesc\n    physical_tensor_desc_infer_fn_(&infer_ctx)\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/user/ops/normalization_op.cpp\", line 159, in operator()\n    CheckParamTensorDesc(\"moving_mean\")\n  File \"/home/ci-user/runners/release/_work/oneflow/oneflow/oneflow/user/ops/normalization_op.cpp\", line 32, in operator()\n    CHECK_EQ_OR_RETURN(tensor_desc.shape(), shape)\nError Type: oneflow.ErrorProto.check_failed_error"
     ]
    }
   ],
   "source": [
    "print(model(torch.randn(1,3,224,224)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10117ec4",
   "metadata": {},
   "source": [
    "为了解决这个问题，我们应该使用\"group pruning\"来从该模型中删除一组参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d2da737",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True).eval()\n",
    "example_inputs = torch.randn(1,3,224,224)\n",
    "\n",
    "# 1. build dependency graph for resnet18\n",
    "DG = tp.DependencyGraph().build_dependency(model, example_inputs=example_inputs)\n",
    "\n",
    "# 2. Select some channels to prune. Here we prune the channels indexed by [2, 6, 9].\n",
    "pruning_idxs = pruning_idxs=[2, 6, 9]\n",
    "group = DG.get_pruning_group( model.conv1, tp.prune_conv_out_channels, idxs=pruning_idxs )\n",
    "\n",
    "group.prune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45a926e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oneflow.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "print(model(torch.randn(1,3,224,224)).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
